{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'mohamed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_by_n(i, n):\n",
    "    return i*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 10, 15, 20]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x * 5, [1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_list_by_n(numbers, n):\n",
    "    return list(map(lambda x, y: x * y, numbers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "func  = lambda y: lambda y: y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 12, 21, 32]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "b = [5,6,7,8]\n",
    "ab = []\n",
    "list(map(lambda x, y: x * y, a, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 12, 21, 32]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,1,1,1\n",
    " 2,2,2,2\n",
    " 3,3,3,3\n",
    " 4,4,4,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d: Input shape: torch.Size([1, 3, 64, 64]), Output shape: torch.Size([1, 64, 64, 64])\n",
      "ReLU: Input shape: torch.Size([1, 64, 64, 64]), Output shape: torch.Size([1, 64, 64, 64])\n",
      "Conv2d: Input shape: torch.Size([1, 64, 64, 64]), Output shape: torch.Size([1, 128, 32, 32])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# A function to register hooks and capture layer-wise input/output shapes\n",
    "def register_hooks(model):\n",
    "    shapes = {}\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        module_name = module.__class__.__name__\n",
    "        shapes[module_name] = {'input_shape': tuple(input[0].shape), 'output_shape': tuple(output.shape)}\n",
    "        print(f\"{module_name}: Input shape: {input[0].shape}, Output shape: {output.shape}\")\n",
    "\n",
    "    # Register hook to all modules\n",
    "    for name, layer in model.named_modules():\n",
    "        if len(list(layer.children())) == 0:  # Register hooks only for the final layers, not containers\n",
    "            layer.register_forward_hook(hook)\n",
    "\n",
    "    return shapes\n",
    "\n",
    "# Define any model or use any custom architecture\n",
    "class ExampleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExampleModel, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and register hooks\n",
    "model = ExampleModel()\n",
    "shapes = register_hooks(model)\n",
    "\n",
    "# Create an example input and pass through the model\n",
    "input_tensor = torch.randn(1, 3, 64, 64)\n",
    "output = model(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from abc import ABC , abstractmethod\n",
    "import math\n",
    "import logging\n",
    "from einops import rearrange\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#######################################################################\n",
    "################################# ABSTRACT BLOCKS #####################\n",
    "#######################################################################\n",
    "class XCBlock(nn.Module):\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "class XBlock(nn.Module):\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "class XTCBlock(nn.Module):\n",
    "    @abstractmethod\n",
    "    def forward(self, x, t, c):\n",
    "        pass\n",
    "\n",
    "class TBlock(nn.Module):\n",
    "    @abstractmethod\n",
    "    def forward(self, t):\n",
    "        pass\n",
    "\n",
    "\n",
    "def zero_module(module):\n",
    "    for p in module.parameters():\n",
    "        p.detach().zero_()\n",
    "    return module\n",
    "\n",
    "\n",
    "class XTBlock(nn.Module):\n",
    "    @abstractmethod\n",
    "    def forward(self, x, t):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Downsample(XBlock):\n",
    "    def __init__(self, scale_factor, mode='nearest'):\n",
    "        super().__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode, recompute_scale_factor=True)\n",
    "\n",
    "\n",
    "\n",
    "class Upsample(XBlock):\n",
    "    def __init__(self, scale_factor, mode='nearest'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)\n",
    "\n",
    "\n",
    "######################################################################\n",
    "########################### TIME EMBEDDING BLOCKS ##########################\n",
    "#####################################################################\n",
    "class SinusoidalTimeEmbedder(TBlock):\n",
    "    def __init__(self, base_channels, max_period = 10000):\n",
    "        super().__init__()\n",
    "        self.base_channels = base_channels\n",
    "        self.max_period = max_period\n",
    "        self.half = base_channels // 2\n",
    "        self.freqs = torch.exp(-math.log(max_period) * torch.arange(self.half, dtype=torch.float32) / self.half)\n",
    "\n",
    "    def forward(self, t):\n",
    "        freqs = self.freqs.to(t.device)\n",
    "        args = t[:, None].float() * freqs\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if self.base_channels % 2:\n",
    "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "        return embedding\n",
    "\n",
    "\n",
    "class LearnableTimeEmbedder(TBlock):\n",
    "    def __init__(self, base_channels, time_embedding_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(base_channels, time_embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embedding_dim, time_embedding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = self.time_embed(t)\n",
    "        return t\n",
    "\n",
    "\n",
    "class TimeEmbedder(TBlock):\n",
    "    def __init__(self, base_channels, time_embedding_dim):\n",
    "        super().__init__()\n",
    "        self.time_embed = nn.Sequential(\n",
    "            SinusoidalTimeEmbedder(base_channels),\n",
    "            LearnableTimeEmbedder(base_channels, time_embedding_dim)\n",
    "        )\n",
    "    def forward(self, t):\n",
    "        return self.time_embed(t)\n",
    "\n",
    "\n",
    "\n",
    "class TimeInjector(XTBlock):\n",
    "    def __init__(self, time_embedding_dim, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embedding_dim, in_channels)\n",
    "        )\n",
    "        self.proj_out = nn.Sequential(\n",
    "                        nn.GroupNorm(32, in_channels),\n",
    "                        nn.SiLU(),\n",
    "                        zero_module(nn.Conv2d(in_channels, in_channels, 3, padding=1))\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        t = self.time_embed(t).type(x.dtype)\n",
    "        while len(t.shape) < len(x.shape):\n",
    "            t = t[..., None]\n",
    "        return self.proj_out(x + t)\n",
    "    \n",
    "############################################################\n",
    "################### CONVOLUTIONAL BLOCKS ###################\n",
    "#############################################################\n",
    "class InConvBlock(XBlock):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_layers = nn.Sequential(\n",
    "            nn.GroupNorm(32, in_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.in_layers(x)\n",
    "    \n",
    "\n",
    "class OutConvBlock(XBlock):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.out_layers = nn.Sequential(\n",
    "            nn.GroupNorm(32, out_channels),\n",
    "            nn.SiLU(),\n",
    "            zero_module(nn.Conv2d(out_channels, out_channels, 3, padding=1))\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.out_layers(x)\n",
    "    \n",
    "\n",
    "\n",
    "class ResBlock(XTBlock):\n",
    "    def __init__(self, in_channels, time_embedding_dim):\n",
    "        super().__init__()\n",
    "        self.inconv = InConvBlock(in_channels, in_channels)\n",
    "        self.injector = TimeInjector(time_embedding_dim, in_channels)\n",
    "    def forward(self, x, t):\n",
    "        h = self.inconv(x)\n",
    "        h = self.injector(h, t)\n",
    "        return x + h   \n",
    "\n",
    "\n",
    "##############################################################\n",
    "############################ MAGIC ###########################\n",
    "##############################################################\n",
    "\n",
    "class Connection:\n",
    "    def __init__(self, start_block, target_block, operation):\n",
    "        self.target_block = target_block\n",
    "        self.start_block = start_block\n",
    "        self.operation = operation\n",
    "        self.collected_tensor = None\n",
    "\n",
    "    def is_target_block(self, name):\n",
    "        return name == self.target_block\n",
    "\n",
    "    def is_start_block(self, name):\n",
    "        return name == self.start_block\n",
    "\n",
    "    def excute_operation(self, x):\n",
    "        return self.operation(x, self.collected_tensor)\n",
    "\n",
    "    def collect(self, x):\n",
    "        self.collected_tensor = x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"Connection(start_block={self.start_block}, \"\n",
    "                f\"target_block={self.target_block}, \"\n",
    "                f\"operation={self.operation.__name__ if hasattr(self.operation, '__name__') else str(self.operation)}, \"\n",
    "                f\"collected_tensor={'Set' if self.collected_tensor is not None else 'None'})\")\n",
    "\n",
    "\n",
    "\n",
    "class Router(nn.Sequential):\n",
    "    def __init__(self, connections, *args):\n",
    "        super(Router, self).__init__(*args)\n",
    "        \n",
    "        self.connections = connections\n",
    "\n",
    "    def forward(self, x, t, c=None):\n",
    "\n",
    "        for block_name, block in self.named_children():\n",
    "            logger.debug(f'{block.__class__.__name__}')\n",
    "            for connection in self.connections:\n",
    "                if connection.is_target_block(block_name):\n",
    "                    x = connection.excute_operation(x)\n",
    "                    logger.debug(f'{x.shape}')\n",
    "\n",
    "            logger.debug(f'{x.shape}')\n",
    "            if isinstance(block, XTBlock):\n",
    "                x = block(x, t)\n",
    "            elif isinstance(block, TBlock):\n",
    "                x = block(t)\n",
    "            elif isinstance(block, XBlock):\n",
    "                x = block(x)\n",
    "            elif isinstance(block, XTCBlock):\n",
    "                x = block(x, t, c)\n",
    "            elif isinstance(block, XCBlock):\n",
    "                x = block(x, c)            \n",
    "            logger.debug(f'{x.shape}')\n",
    "\n",
    "            for connection in self.connections:\n",
    "                if connection.is_start_block(block_name):\n",
    "                    connection.collect(x)\n",
    "        return x\n",
    "    \n",
    "class ChannelChanger(XBlock):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "def connection_finder(unet, name):\n",
    "    names = []\n",
    "    left = []\n",
    "    right = []\n",
    "    for i, block in enumerate(unet):\n",
    "        if block.__class__.__name__ == name:\n",
    "            names.append(str(i))\n",
    "    \n",
    "    while len(names) != 1:\n",
    "        left.append(names.pop(0))\n",
    "        right.append(names.pop())\n",
    "\n",
    "    connections = [Connection(first, second, concat) for first, second in zip(left, right)]\n",
    "    logger.debug(f'left: {left}')\n",
    "    logger.debug(f'right: {right}')\n",
    "\n",
    "    return connections\n",
    "\n",
    "\n",
    "\n",
    "def concat(x, y):\n",
    "    return torch.cat([x, y], dim=1)\n",
    "\n",
    "################################################################\n",
    "################### ATTENTION BLOCKS ###########################\n",
    "################################################################\n",
    "                    \n",
    "class CrossAttention(XCBlock):\n",
    "    def __init__(self, d_query, d_context, n_heads, head_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        inner_dim = n_heads*head_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.scale = head_dim**-0.5\n",
    "        \n",
    "        self.Q = nn.Linear(d_query, inner_dim, bias=False)\n",
    "        self.K = nn.Linear(d_context, inner_dim, bias=False)\n",
    "        self.V = nn.Linear(d_context, inner_dim, bias=False)\n",
    "        \n",
    "        self.proj_out = nn.Linear(inner_dim, d_query)\n",
    "        self.norm = nn.LayerNorm(d_query)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        h = self.norm(x)\n",
    "        \n",
    "        Q = self.Q(h)\n",
    "        K = self.K(context)\n",
    "        V = self.V(context)\n",
    "\n",
    "        Q, K, V = map(lambda t: rearrange( t, 'b n (h d) -> (b h) n d', h=self.n_heads), (Q, K, V))\n",
    "\n",
    "        attention = torch.einsum('b i d, b j d -> b i j', Q, K)\n",
    "        attention = attention.softmax(dim=-1)\n",
    "        attention = attention*self.scale\n",
    "\n",
    "        values = torch.einsum('b i j, b j d -> b i d', attention, V)\n",
    "        values = rearrange(values, '(b h) n d -> b n (h d)', h=self.n_heads)\n",
    "        values = self.proj_out(values)\n",
    "        return x + values\n",
    "\n",
    "\n",
    "class SelfAttention(XBlock):\n",
    "    def __init__(self, d, n_heads, head_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        inner_dim = n_heads*head_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.scale  = head_dim**-0.5\n",
    "        \n",
    "        self.Q = nn.Linear(d, inner_dim, bias=False)\n",
    "        self.K = nn.Linear(d, inner_dim, bias=False)\n",
    "        self.V = nn.Linear(d, inner_dim, bias=False)\n",
    "        \n",
    "        self.proj_out = nn.Linear(inner_dim, d)\n",
    "        self.norm = nn.LayerNorm(d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.norm(x)\n",
    "        \n",
    "        Q = self.Q(h)\n",
    "        K = self.K(h)\n",
    "        V = self.V(h)\n",
    "\n",
    "        Q, K, V = map(lambda t: rearrange( t, 'b n (h d) -> (b h) n d', h=self.n_heads), (Q, K, V))\n",
    "\n",
    "        attention = torch.einsum('b i d, b j d -> b i j', Q, K)\n",
    "        attention = attention.softmax(dim=-1)\n",
    "        attention = attention*self.scale\n",
    "\n",
    "        values = torch.einsum('b i j, b j d -> b i d', attention, V)\n",
    "        values = rearrange(values, '(b h) n d -> b n (h d)', h=self.n_heads)\n",
    "        values = self.proj_out(values)\n",
    "        return x + values \n",
    "\n",
    "class GEGLU(XBlock):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.proj = nn.Linear(dim_in, dim_out * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x, gate = self.proj(x).chunk(2, dim=-1)\n",
    "        \n",
    "        return x * F.gelu(gate)\n",
    "    \n",
    "\n",
    "class FeedForwardGEGLU(XBlock):\n",
    "    def __init__(self, d_query, dropout=0.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(nn.LayerNorm(d_query),\n",
    "            GEGLU(d_query, d_query*4),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_query*4, d_query)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x) + x\n",
    "    \n",
    "class FeedForwardGLU(XBlock):\n",
    "    def __init__(self, d_query, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.LayerNorm(d_query),\n",
    "            nn.Linear(d_query, 4*d_query),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(4*d_query, d_query)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x) + x\n",
    "    \n",
    "\n",
    "class Adapter(XBlock):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return rearrange(x , 'b c h w -> b (h w) c')\n",
    "    \n",
    "    \n",
    "class UnetBlock(XTCBlock):\n",
    "    def __init__(self,\n",
    "                  in_channels,\n",
    "                  context_dim=128,\n",
    "                  time_embedding_dim=128,\n",
    "                  n_heads=8,\n",
    "                  head_dim=32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.block = Router([],\n",
    "            *[\n",
    "            ResBlock(in_channels, time_embedding_dim),\n",
    "            Adapter(),\n",
    "            SelfAttention(in_channels, n_heads, head_dim),\n",
    "            CrossAttention(in_channels, context_dim, n_heads, head_dim),\n",
    "            FeedForwardGEGLU(in_channels)   \n",
    "            ]\n",
    "        )\n",
    "    def forward(self, x, t, context):\n",
    "        _, _, h, w = x.shape\n",
    "        x = self.block(x, t, context)\n",
    "        return rearrange(x , 'b (h w) c -> b c h w', h=h, w=w)\n",
    "\n",
    "#######################################################\n",
    "####################### UNET ##########################\n",
    "#######################################################\n",
    "\n",
    "class ResChain(XTBlock):\n",
    "    def __init__(self, in_channels, num_resblocks, time_embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.resblocks = nn.ModuleList(\n",
    "            [\n",
    "                ResBlock(in_channels, time_embedding_dim) for _ in range(num_resblocks)\n",
    "            ]\n",
    "                        \n",
    "        )\n",
    "  \n",
    "\n",
    "    def forward(self, x, t):\n",
    "        for block in self.resblocks:\n",
    "            x = block(x, t)\n",
    "        return x\n",
    "    \n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, channels=[64, 128, 256, 512], num_resblocks=5):\n",
    "        super().__init__()        \n",
    "        self.in_proj = nn.Conv2d(1, channels[0], 3, padding=1)\n",
    "        self.out_proj = nn.Conv2d(channels[0], 1, 3, padding=1)\n",
    "\n",
    "        self.time_embedder = TimeEmbedder(channels[0], time_embedding_dim=128)\n",
    "        \n",
    "        \n",
    "        self.down = []\n",
    "        for i in range(len(channels)-1):\n",
    "            self.down.append(ResChain(channels[i], num_resblocks))\n",
    "            self.down.append(Downsample(0.5, 'nearest'))\n",
    "            self.down.append(ChannelChanger(channels[i], channels[i+1]))\n",
    "        \n",
    "        self.mid = [ResChain(channels[-1], num_resblocks)]\n",
    "\n",
    "        channels_reversed = list(reversed(channels))\n",
    "        self.up = []\n",
    "        for i in range(len(channels_reversed)-1):\n",
    "            self.up.append(Upsample(2, 'nearest'))\n",
    "            self.up.append(ChannelChanger(channels_reversed[i], channels_reversed[i+1]))\n",
    "            self.up.append(ResChain(2*channels_reversed[i+1], num_resblocks))\n",
    "            self.up.append(ChannelChanger(2*channels_reversed[i+1], channels_reversed[i+1]))\n",
    "\n",
    "        unet = self.down + self.mid + self.up\n",
    "        connections = connection_finder(unet, 'ResChain')\n",
    "        self.unet = Router(connections, *unet)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = self.time_embedder(t)\n",
    "        x = self.in_proj(x)\n",
    "        x = self.unet(x, t)\n",
    "        return self.out_proj(x) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:43:09,149 - DEBUG - left: ['0', '3', '6']\n",
      "2024-11-14 17:43:09,149 - DEBUG - right: ['20', '16', '12']\n"
     ]
    }
   ],
   "source": [
    "model = Unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 512])\n",
      "torch.Size([4, 8, 512])\n",
      "torch.Size([4, 8, 512])\n"
     ]
    }
   ],
   "source": [
    "att1 = CrossAttention(512, 128, 8, 32)\n",
    "att2 = SelfAttention(512, 8, 32)\n",
    "trans = TransformerBlock(512, 128, 8, 32)\n",
    "x = torch.randn(4, 8, 512)\n",
    "context = torch.randn((4, 4, 128))\n",
    "print(att1(x, context).shape)\n",
    "print(att2(x).shape)\n",
    "print(trans(x, context).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 4, 4])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels = 512\n",
    "n_heads = 8\n",
    "head_dim = 32\n",
    "context_dim = 128\n",
    "time_embedding_dim = 128\n",
    "\n",
    "\n",
    "x = torch.randn(4, 512, 4, 4)\n",
    "context = torch.randn((4, 4, 128))\n",
    "embed = TimeEmbedder(base_channels=64, time_embedding_dim=128)\n",
    "t = embed(torch.tensor(100)[None])\n",
    "\n",
    "block = UnetBlock(in_channels=512)\n",
    "\n",
    "block(x, t, context).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:45:54,676 - DEBUG - ResChain\n",
      "2024-11-14 17:45:54,676 - DEBUG - torch.Size([1, 64, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:45:54,790 - DEBUG - torch.Size([1, 64, 128, 128])\n",
      "2024-11-14 17:45:54,790 - DEBUG - Downsample\n",
      "2024-11-14 17:45:54,790 - DEBUG - torch.Size([1, 64, 128, 128])\n",
      "2024-11-14 17:45:54,790 - DEBUG - torch.Size([1, 64, 64, 64])\n",
      "2024-11-14 17:45:54,790 - DEBUG - ChannelChanger\n",
      "2024-11-14 17:45:54,790 - DEBUG - torch.Size([1, 64, 64, 64])\n",
      "2024-11-14 17:45:54,790 - DEBUG - torch.Size([1, 128, 64, 64])\n",
      "2024-11-14 17:45:54,799 - DEBUG - ResChain\n",
      "2024-11-14 17:45:54,799 - DEBUG - torch.Size([1, 128, 64, 64])\n",
      "2024-11-14 17:45:54,846 - DEBUG - torch.Size([1, 128, 64, 64])\n",
      "2024-11-14 17:45:54,846 - DEBUG - Downsample\n",
      "2024-11-14 17:45:54,846 - DEBUG - torch.Size([1, 128, 64, 64])\n",
      "2024-11-14 17:45:54,846 - DEBUG - torch.Size([1, 128, 32, 32])\n",
      "2024-11-14 17:45:54,846 - DEBUG - ChannelChanger\n",
      "2024-11-14 17:45:54,846 - DEBUG - torch.Size([1, 128, 32, 32])\n",
      "2024-11-14 17:45:54,860 - DEBUG - torch.Size([1, 256, 32, 32])\n",
      "2024-11-14 17:45:54,861 - DEBUG - ResChain\n",
      "2024-11-14 17:45:54,861 - DEBUG - torch.Size([1, 256, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:45:54,901 - DEBUG - torch.Size([1, 256, 32, 32])\n",
      "2024-11-14 17:45:54,901 - DEBUG - Downsample\n",
      "2024-11-14 17:45:54,901 - DEBUG - torch.Size([1, 256, 32, 32])\n",
      "2024-11-14 17:45:54,909 - DEBUG - torch.Size([1, 256, 16, 16])\n",
      "2024-11-14 17:45:54,910 - DEBUG - ChannelChanger\n",
      "2024-11-14 17:45:54,911 - DEBUG - torch.Size([1, 256, 16, 16])\n",
      "2024-11-14 17:45:54,915 - DEBUG - torch.Size([1, 512, 16, 16])\n",
      "2024-11-14 17:45:54,915 - DEBUG - ResChain\n",
      "2024-11-14 17:45:54,915 - DEBUG - torch.Size([1, 512, 16, 16])\n",
      "2024-11-14 17:45:54,949 - DEBUG - torch.Size([1, 512, 16, 16])\n",
      "2024-11-14 17:45:54,949 - DEBUG - Upsample\n",
      "2024-11-14 17:45:54,949 - DEBUG - torch.Size([1, 512, 16, 16])\n",
      "2024-11-14 17:45:54,963 - DEBUG - torch.Size([1, 512, 32, 32])\n",
      "2024-11-14 17:45:54,964 - DEBUG - ChannelChanger\n",
      "2024-11-14 17:45:54,964 - DEBUG - torch.Size([1, 512, 32, 32])\n",
      "2024-11-14 17:45:54,971 - DEBUG - torch.Size([1, 256, 32, 32])\n",
      "2024-11-14 17:45:54,971 - DEBUG - ResChain\n",
      "2024-11-14 17:45:54,974 - DEBUG - torch.Size([1, 512, 32, 32])\n",
      "2024-11-14 17:45:54,974 - DEBUG - torch.Size([1, 512, 32, 32])\n",
      "2024-11-14 17:45:55,097 - DEBUG - torch.Size([1, 512, 32, 32])\n",
      "2024-11-14 17:45:55,097 - DEBUG - ChannelChanger\n",
      "2024-11-14 17:45:55,097 - DEBUG - torch.Size([1, 512, 32, 32])\n",
      "2024-11-14 17:45:55,113 - DEBUG - torch.Size([1, 256, 32, 32])\n",
      "2024-11-14 17:45:55,113 - DEBUG - Upsample\n",
      "2024-11-14 17:45:55,113 - DEBUG - torch.Size([1, 256, 32, 32])\n",
      "2024-11-14 17:45:55,113 - DEBUG - torch.Size([1, 256, 64, 64])\n",
      "2024-11-14 17:45:55,113 - DEBUG - ChannelChanger\n",
      "2024-11-14 17:45:55,113 - DEBUG - torch.Size([1, 256, 64, 64])\n",
      "2024-11-14 17:45:55,125 - DEBUG - torch.Size([1, 128, 64, 64])\n",
      "2024-11-14 17:45:55,126 - DEBUG - ResChain\n",
      "2024-11-14 17:45:55,127 - DEBUG - torch.Size([1, 256, 64, 64])\n",
      "2024-11-14 17:45:55,127 - DEBUG - torch.Size([1, 256, 64, 64])\n",
      "2024-11-14 17:45:55,245 - DEBUG - torch.Size([1, 256, 64, 64])\n",
      "2024-11-14 17:45:55,245 - DEBUG - ChannelChanger\n",
      "2024-11-14 17:45:55,245 - DEBUG - torch.Size([1, 256, 64, 64])\n",
      "2024-11-14 17:45:55,253 - DEBUG - torch.Size([1, 128, 64, 64])\n",
      "2024-11-14 17:45:55,253 - DEBUG - Upsample\n",
      "2024-11-14 17:45:55,253 - DEBUG - torch.Size([1, 128, 64, 64])\n",
      "2024-11-14 17:45:55,253 - DEBUG - torch.Size([1, 128, 128, 128])\n",
      "2024-11-14 17:45:55,253 - DEBUG - ChannelChanger\n",
      "2024-11-14 17:45:55,253 - DEBUG - torch.Size([1, 128, 128, 128])\n",
      "2024-11-14 17:45:55,268 - DEBUG - torch.Size([1, 64, 128, 128])\n",
      "2024-11-14 17:45:55,269 - DEBUG - ResChain\n",
      "2024-11-14 17:45:55,271 - DEBUG - torch.Size([1, 128, 128, 128])\n",
      "2024-11-14 17:45:55,272 - DEBUG - torch.Size([1, 128, 128, 128])\n",
      "2024-11-14 17:45:55,424 - DEBUG - torch.Size([1, 128, 128, 128])\n",
      "2024-11-14 17:45:55,425 - DEBUG - ChannelChanger\n",
      "2024-11-14 17:45:55,425 - DEBUG - torch.Size([1, 128, 128, 128])\n",
      "2024-11-14 17:45:55,431 - DEBUG - torch.Size([1, 64, 128, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 128])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 128, 128)\n",
    "t = torch.randint(1000 , size=(1,))\n",
    "model(x, t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 127\u001b[0m\n\u001b[0;32m    125\u001b[0m schedule \u001b[38;5;241m=\u001b[39m LinearSchedule()\n\u001b[0;32m    126\u001b[0m diffusion \u001b[38;5;241m=\u001b[39m Diffusion(schedule)\n\u001b[1;32m--> 127\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m#print(data[0].compute().shape)\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m#x = torch.randn(512, 512)\u001b[39;00m\n\u001b[0;32m    130\u001b[0m xt, noise \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39madd_noise(x, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;28;01mNone\u001b[39;00m])\n",
      "File \u001b[1;32mc:\\Users\\mhesh\\OneDrive\\Desktop\\projee\\venv\\Lib\\site-packages\\dask\\base.py:372\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\mhesh\\OneDrive\\Desktop\\projee\\venv\\Lib\\site-packages\\dask\\base.py:660\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 660\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from functools import partial\n",
    "from inspect import isfunction\n",
    "from refactor.schedules import extract_into_tensor, exists, default, LinearSchedule, BetaSchedule\n",
    "import matplotlib.pyplot as plt\n",
    "from data.LoadData import load_single_aws_zarr, AWS_ZARR_ROOT\n",
    "to_torch = partial(torch.tensor, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import s3fs\n",
    "import zarr\n",
    "from typing import Union\n",
    "import dask.array as da\n",
    "\n",
    "AWS_ZARR_ROOT = (\n",
    "    \"s3://gov-nasa-hdrl-data1/contrib/fdl-sdoml/fdl-sdoml-v2/sdomlv2.zarr/\"\n",
    ")\n",
    "\n",
    "\n",
    "def s3_connection(path_to_zarr: os.path) -> s3fs.S3Map:\n",
    "    \"\"\"\n",
    "    Instantiate connection to aws for a given path `path_to_zarr`\n",
    "    \"\"\"\n",
    "    return s3fs.S3Map(\n",
    "        root=path_to_zarr,\n",
    "        s3=s3fs.S3FileSystem(anon=True),\n",
    "        # anonymous access requires no credentials\n",
    "        check=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_single_aws_zarr(\n",
    "    path_to_zarr: os.path,\n",
    "    cache_max_single_size: int = None,\n",
    "    wavelength='171A',\n",
    ") -> Union[zarr.Array, zarr.Group]:\n",
    "    \"\"\"\n",
    "    load zarr from s3 using LRU cache\n",
    "    \"\"\"\n",
    "    root = zarr.open(\n",
    "            zarr.LRUStoreCache(\n",
    "                store=s3_connection(path_to_zarr),\n",
    "                max_size=cache_max_single_size,\n",
    "            ),\n",
    "            mode=\"r\",\n",
    "         )\n",
    "    data = root[wavelength]\n",
    "    data = da.from_array(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "data = load_single_aws_zarr(\n",
    "        path_to_zarr=AWS_ZARR_ROOT + str(2015),\n",
    "        wavelength='171A'\n",
    "    )\n",
    "class Diffusion(nn.Module):\n",
    "    def __init__(self,\n",
    "                schedule: BetaSchedule,\n",
    "                parameterization: str ='eps',\n",
    "                v_posterior: float = 0.0\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.parameterization = parameterization\n",
    "        self.v_posterior = v_posterior\n",
    "        self.schedule = schedule\n",
    "        self.register_schedule()\n",
    "\n",
    "    def register_schedule(self):\n",
    "        \n",
    "        betas =  self.schedule.betas().numpy()\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n",
    "        assert alphas_cumprod.shape[0] == self.schedule.timesteps\n",
    "        \n",
    "        self.register_buffer('betas', to_torch(betas))\n",
    "        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n",
    "        self.register_buffer('alphas_cumprod_prev', to_torch(alphas_cumprod_prev))\n",
    "\n",
    "        self.register_buffer('sqrt_alphas_cumprod', to_torch(np.sqrt(alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod', to_torch(np.sqrt(1. - alphas_cumprod)))\n",
    "        self.register_buffer('log_one_minus_alphas_cumprod', to_torch(np.log(1. - alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recip_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recipm1_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n",
    "\n",
    "        posterior_variance = (1 - self.v_posterior) * betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod) + self.v_posterior * betas\n",
    "        \n",
    "        self.register_buffer('posterior_variance', to_torch(posterior_variance))\n",
    "        self.register_buffer('posterior_log_variance_clipped', to_torch(np.log(np.maximum(posterior_variance, 1e-20))))\n",
    "        self.register_buffer('posterior_mean_coef1', to_torch(betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n",
    "        self.register_buffer('posterior_mean_coef2', to_torch((1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n",
    "\n",
    "\n",
    "        if self.parameterization == \"eps\":\n",
    "            lvlb_weights = self.betas ** 2 / (2 * self.posterior_variance * to_torch(alphas) * (1 - self.alphas_cumprod))\n",
    "        elif self.parameterization == \"x0\":\n",
    "            lvlb_weights = 0.5 * np.sqrt(torch.Tensor(alphas_cumprod)) / (2. * 1 - torch.Tensor(alphas_cumprod))\n",
    "        else:\n",
    "            raise NotImplementedError(\"mu not supported\")\n",
    "        \n",
    "        # TODO how to choose this term\n",
    "        lvlb_weights[0] = lvlb_weights[1]\n",
    "        self.register_buffer('lvlb_weights', lvlb_weights, persistent=False)\n",
    "        assert not torch.isnan(self.lvlb_weights).all()\n",
    "    \n",
    "    def add_noise(self, x0, t):\n",
    "        noise = torch.randn_like(x0)\n",
    "        \n",
    "        sqrt_alphas_cumprod = extract_into_tensor(self.sqrt_alphas_cumprod, t, x0.shape)\n",
    "        sqrt_one_minus_alphas_cumprod = extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x0.shape)\n",
    "        \n",
    "        xt = sqrt_alphas_cumprod * x0 + sqrt_one_minus_alphas_cumprod * noise\n",
    "        return xt, noise\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    schedule = LinearSchedule()\n",
    "    diffusion = Diffusion(schedule)\n",
    "    x = data[0].compute()\n",
    "    #print(data[0].compute().shape)\n",
    "    #x = torch.randn(512, 512)\n",
    "    xt, noise = diffusion.add_noise(x, torch.tensor(1)[None])\n",
    "    plt.imshow(xt.cpu().numpy(), cmap='afmhot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_single_aws_zarr(path_to_zarr=AWS_ZARR_ROOT + str(2015), wavelength='171A')\n",
    "#data[0].compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9981)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.nn.MSELoss()(torch.randn(1, 1, 4, 512, 512), torch.randn(1, 1, 4, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = down_blocks + middle_blocks + up_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = [Connection('0','12', concat),\n",
    "               Connection('2','10', concat),\n",
    "               Connection('4','8', concat)\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhesh\\OneDrive\\Desktop\\projee\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mhesh\\OneDrive\\Desktop\\projee\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\mhesh/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:55<00:00, 9.92MB/s] \n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "vgg = models.vgg16(pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
